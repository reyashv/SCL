import matplotlib.pyplot as plt
import numpy as np

def divided_difference(x, fx):
    n = len(x)
    table = [[0] * n for i in range(n)]

    for i in range(n):
        table[i][0] = fx[i]

    for j in range(1, n):
        for i in range(n - j):
            table[i][j] = (table[i + 1][j - 1] - table[i][j - 1]) / (x[i + j] - x[i])

    return table

def interpolate(x, fx, target_x):
    n = len(x)
    result = 0
    table = divided_difference(x, fx)

    for i in range(n):
        term = table[0][i]
        for j in range(i):
            term *= (target_x - x[j])
        result += term

    return result

x1 = [654, 658, 659, 661]
fx1 = [2.8156, 2.8182, 2.8189, 2.8202]

x2 = [0, 0.1, 0.2, 0.3, 0.4]
fx2 = [1, 1.1052, 1.2214, 1.3499, 1.4918]

target_x1 = 656
result1 = interpolate(x1, fx1, target_x1)
print(f"f({target_x1}) = {result1:.4f}")

target_x2 = 0.38
result2 = interpolate(x2, fx2, target_x2)
print(f"e({target_x2}) = {result2:.4f}")

table1 = divided_difference(x1, fx1)
table2 = divided_difference(x2, fx2)
print("\nDivided Difference Table (a):")
for row in table1:
    print(row)
print("\nDivided Difference Table (b):")
for row in table2:
    print(row)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.scatter(x1, fx1, label='Data Points (a)')
x_values1 = np.linspace(min(x1), max(x1), 100)
y_values1 = [interpolate(x1, fx1, x) for x in x_values1]
plt.plot(x_values1, y_values1, label='Interpolated Polynomial (a)')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.title('Interpolation for Data Points (a)')
plt.legend()

plt.subplot(1, 2, 2)
plt.scatter(x2, fx2, label='Data Points (b)')
x_values2 = np.linspace(min(x2), max(x2), 100)
y_values2 = [interpolate(x2, fx2, x) for x in x_values2]
plt.plot(x_values2, y_values2, label='Interpolated Polynomial (b)')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.title('Interpolation for Data Points (b)')
plt.legend()

plt.tight_layout()
plt.show()
